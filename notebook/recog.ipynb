{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import * \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, ConcatDataset, Subset, DataLoader\n",
    "\n",
    "import torchvision.transforms as VT\n",
    "\n",
    "\n",
    "from iqradre.recog.data import dataset\n",
    "from iqradre.recog.models import crnn_v1 as crnn\n",
    "\n",
    "import iqradre.recog.transforms as NT\n",
    "from iqradre.recog.data.dataset import LMDBDataset, BalanceDatasetConcatenator\n",
    "from iqradre.recog.data import loader\n",
    "from iqradre.recog.utils import AttnLabelConverter\n",
    "from iqradre.recog.trainer.task import TaskOCR\n",
    "\n",
    "import torchvision.transforms as VT\n",
    "from iqradre.recog import transforms as NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "BATCH_MAX_LENGTH = 25\n",
    "SHUFFLE = True\n",
    "USAGE_RATIO = (0.5, 0.5)\n",
    "SENSITIVE = True\n",
    "CHARACTER = string.printable[:-6]\n",
    "IMG_SIZE = (32,100)\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "LRATE = 1.0\n",
    "\n",
    "GRAD_CLIP = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINSET_PATH = '/data/lmdb/data_lmdb_release/training'\n",
    "VALIDSET_PATH = '/data/lmdb/data_lmdb_release/validation'\n",
    "\n",
    "trainloader, trainset = loader.train_loader(TRAINSET_PATH, batch_size=BATCH_SIZE, \n",
    "                                  shuffle=SHUFFLE, num_workers=NUM_WORKERS,\n",
    "                                  img_size=IMG_SIZE, usage_ratio=USAGE_RATIO,\n",
    "                                  is_sensitive=SENSITIVE, character=CHARACTER)\n",
    "\n",
    "validloader, validset = loader.valid_loader(VALIDSET_PATH, batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True, num_workers=NUM_WORKERS,\n",
    "                                  img_size=IMG_SIZE, is_sensitive=SENSITIVE,\n",
    "                                  character=CHARACTER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iqradre.recog.utils import AttnLabelConverter\n",
    "CHARACTER = string.printable[:-6]\n",
    "converter = AttnLabelConverter(CHARACTER)\n",
    "NUM_CLASS = len(converter.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPredictor(object):\n",
    "    def __init__(self, weight_path, device='cpu'):\n",
    "        self.weight_path = weight_path\n",
    "        self.device = device\n",
    "        self._load_config()\n",
    "        \n",
    "    def _load_config(self):\n",
    "        self.character = string.printable[:-6]\n",
    "        self.converter = AttnLabelConverter(self.character)\n",
    "        self.num_class = len(converter.character)\n",
    "        self.batch_max_length = 25\n",
    "        self.img_size = (32, 100)\n",
    "        \n",
    "        \n",
    "    def _load_model(self):\n",
    "        state_dict = torch.load(self.weight_path, map_location=torch.device(self.device))\n",
    "        self.model = crnn_v1.OCRNet(num_class=self.num_class, im_size=self.img_size, hidden_size=256)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        \n",
    "    def _predict(self, images:list):\n",
    "        data = self._transform(images)\n",
    "        batch_size = data.shape[0]\n",
    "        \n",
    "        length = torch.IntTensor([self.batch_max_length] * batch_size)\n",
    "        preds = self.model(images)\n",
    "        preds = preds[:, :self.batch_max_length, :]\n",
    "        _, preds_index = preds.max(2)\n",
    "        preds_str = self.converter.decode(preds_index, length)\n",
    "        preds_clean = self._clean_prediction(preds_str)\n",
    "        return preds_clean\n",
    "    \n",
    "    def _clean_prediction(preds_str):\n",
    "        out = []\n",
    "        for prd_st in preds_str:\n",
    "            word = prd_st.split(\"[s]\")[0]\n",
    "            out.append(word)\n",
    "        return out\n",
    "    \n",
    "    def _transform(self, images):\n",
    "        transform = VT.Compose([\n",
    "            NT.ResizeRatioWithRightPad(size=self.img_size),\n",
    "            VT.ToTensor(),\n",
    "            VT.Normalize(mean=(0.5), std=(0.5))\n",
    "        ])\n",
    "        \n",
    "        return transform(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = '../weights/recog/ocrnet_pretrained_ktp.pth'\n",
    "state_dict = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "model = crnn.OCRNet(num_class=NUM_CLASS, im_size=IMG_SIZE, hidden_size=256)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_for_pred = torch.IntTensor([BATCH_MAX_LENGTH] * BATCH_SIZE)\n",
    "preds = model(images)\n",
    "preds = preds[:, :BATCH_MAX_LENGTH, :]\n",
    "_, preds_index = preds.max(2)\n",
    "preds_str = converter.decode(preds_index, length_for_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prediction_string(pred_str):\n",
    "    out = []\n",
    "    for prd_st in preds_str:\n",
    "        word = prd_st.split(\"[s]\")[0]\n",
    "        out.append(word)\n",
    "    return out\n",
    "\n",
    "clean_preds_str = clean_prediction_string(preds_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jemasan[s]an[s]asta[s][s][s][s]a[s][s]a[s][s]',\n",
       " 'CRI[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]',\n",
       " 'L/n[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]',\n",
       " 'PING[s][s][s][s][s]G[s][s][s][s][s][s][s][s][s][s][s][s][s][s][s]']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jemasan', 'CRI', 'L/n', 'PING']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_preds_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
